{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器 optimizers\n",
    "\n",
    "优化器是编译 Keras 模型必要的两个参数之一。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, kernel_initializer='uniform', input_shape=(10,)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以在调用 model.compile() 之前初始化一个优化器对象，然后传入该函数（如上所示），也可以在调用 model.compile() 时传递一个预定义优化器名。在后者情形下，优化器的参数将使用默认值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass optimizer by name: default parameters will be used\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 所有优化器都可用的参数\n",
    "\n",
    "参数 clipnorm 和 clipvalue 是所有优化器都可以使用的参数，用于对梯度进行裁剪，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "# All parameter gradients will be clipped to\n",
    "# a maximum norm of 1.\n",
    "sgd = optimizers.SGD(lr=0.01, clipnorm=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "# All parameter gradients will be clipped to\n",
    "# a maximum value of 0.5 and\n",
    "# a minimum value of -0.5.\n",
    "sgd = optimizers.SGD(lr=0.01, clipvalue=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机梯度下降法，支持动量参数，支持学习率减衰，支持 Nesterov 动量。\n",
    "\n",
    "### 参数\n",
    "\n",
    "* lr: 大或等于 0 的浮点数，学习率\n",
    "* momentum: 大或等于 0 的浮点数，动量参数\n",
    "* decay: 大或等于 0 的浮点数，每次更新后的学习率衰减值\n",
    "* nesterov: 布尔值，确定是否使用 Nesterov 动量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=1e-06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除学习率可调整外，建议保持优化器的其他默认参数不变\n",
    "\n",
    "该优化器通常是面对递归神经网络时的一个良好选择\n",
    "\n",
    "参数\n",
    "* lr：大或等于0的浮点数，学习率\n",
    "* rho：大或等于0的浮点数\n",
    "* epsilon：大或等于0的小浮点数，防止除0错误"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.Adagrad(lr=0.01, epsilon=1e-06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建议保持优化器的默认参数不变\n",
    "\n",
    "Adagrad\n",
    "* lr：大或等于0的浮点数，学习率\n",
    "* epsilon：大或等于0的小浮点数，防止除0错误"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建议保持优化器的默认参数不变\n",
    "\n",
    "参数\n",
    "* lr：大或等于0的浮点数，学习率\n",
    "* rho：大或等于0的浮点数\n",
    "* epsilon：大或等于0的小浮点数，防止除0错误"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该优化器的默认值来源于参考文献\n",
    "\n",
    "参数\n",
    "* lr：大或等于0的浮点数，学习率\n",
    "* beta_1/beta_2：浮点数， 0<beta<1，通常很接近1\n",
    "* epsilon：大或等于0的小浮点数，防止除0错误"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adamax优化器来自于Adam的论文的Section7，该方法是基于无穷范数的Adam方法的变体。\n",
    "\n",
    "默认参数由论文提供\n",
    "\n",
    "参数\n",
    "* lr：大或等于0的浮点数，学习率\n",
    "* beta_1/beta_2：浮点数， 0<beta<1，通常很接近1\n",
    "* epsilon：大或等于0的小浮点数，防止除0错误"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesterov Adam optimizer: Adam本质上像是带有动量项的RMSprop，Nadam就是带有Nesterov 动量的Adam RMSprop\n",
    "\n",
    "默认参数来自于论文，推荐不要对默认参数进行更改。\n",
    "\n",
    "参数\n",
    "* lr：大或等于0的浮点数，学习率\n",
    "* beta_1/beta_2：浮点数， 0<beta<1，通常很接近1\n",
    "* epsilon：大或等于0的小浮点数，防止除0错误"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.TFOptimizer(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF优化器的包装器"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
